Example3 Image Editing Pipeline Documentation

Overview
Example3 is an automated image editing pipeline capable of performing intelligent image editing with background preservation. This pipeline trains text embeddings and a LoRA model, combined with an attention mechanism to automatically generate foreground masks, ultimately producing edited images that retain the original background.

Pipeline Execution Flow

Step 1: Data Preparation
Execution Script: prepare_edit.sh
Function Description:
• Generates segmentation files (in JSONL format) for the training dataset
• Extracts multi-scale encoded features from images
• Prepares necessary data structures for subsequent training

Key Parameters:
• Automatically sets the base path to the current example directory
• Uses a pre-trained VAE model for feature extraction

Step 2: Text Embedding Training
Execution Script: train_EditInfinity_example3.sh
Function Description:
• Trains the text embedding model to learn the mapping from text to image
• Provides semantic understanding capabilities for image editing

Training Parameters:
• train_textembedding=1: Enables text embedding training
• train_textembedding_iter=10: Trains for 10 iterations
• use_textembedding=0: Does not use pre-trained embeddings during training
• train_lora=0: Does not train LoRA in this stage

Step 3: LoRA Model Training
Execution Script: train_EditInfinity_example3.sh
Function Description:
• Trains the LoRA (Low-Rank Adaptation) model based on the pre-trained text embeddings
• LoRA provides finer control over image editing

Training Parameters:
• train_textembedding=0: Stops text embedding training
• use_textembedding=1: Uses the text embeddings trained in Step 2
• use_textembedding_iter=10: Uses embedding weights from the 10th iteration
• train_lora=1: Enables LoRA training
• train_lora_iter=20: Trains for 20 iterations

Step 4: Attention Map Generation
Execution Script: get_targetword_attentionmap_example3.sh
Function Description:
• Uses the trained model to generate attention maps for target words
• Attention maps identify foreground regions in the image that need editing

Key Settings:
• infer_function=1: Specifically used for generating attention maps
• Automatically sets inference paths and subdirectories

Step 5: Mask and Weight Tensor Generation
Execution Script: get_weighted_tensor.sh
Function Description:
• Generates foreground mask images based on attention maps
• Creates weight tensors for background preservation
• Produces visual analysis images of attention maps

Processing Content:
• Automatically sets base paths and case paths
• Generates mask.png (foreground mask)
• Generates attention_analysis.png (attention analysis diagram)
• Generates weight tensors for background preservation

Step 6: Final Image Inference
Execution Script: infer_EditInfinity_example3.sh
Function Description:
• Uses the trained text embeddings and LoRA model
• Combines generated masks and weight tensors
• Produces the final edited image while preserving the original background

Inference Parameters:
• infer_function=2: Used for final image generation
• use_concat_embedding=1: Uses concatenated text embeddings
• use_embedding_iter=10: Uses embeddings from the 10th iteration
• use_lora=1: Uses the LoRA model
• use_lora_iter=20: Uses LoRA weights from the 20th iteration

Technical Features
Background Preservation Mechanism
• No need for manually provided mask images
• Automatically identifies foreground and background through attention mechanisms
• Intelligently calculates background preservation weights

Two-Stage Training Strategy
1. Text Embedding Training: Learns the mapping from text semantics to visual features
2. LoRA Fine-Tuning Training: Performs detailed adjustments based on the embeddings

Automation Level
• All paths are set automatically, no manual modification required
• Parameters are configured automatically to reduce human error
• Complete end-to-end processing flow

Output Results
After the pipeline execution is complete, the following will be generated in the specified directory:
• Trained model weight files
• Attention maps and analysis images
• Foreground mask images
• Final edited images (with original background preserved)

Usage Instructions
1. Ensure all dependency environments are correctly installed
2. Place the image to be edited at image/original_image.jpg
3. Write the original image prompt into prompt/original_image_prompt.txt
4. Write the edit prompt into prompt/edit_image_prompt.txt
5. Write the target prompt into prompt/target_word.txt
6. Run edit_pipeline.sh to start the automated processing
7. After processing is complete, results will be saved in the corresponding output directory
