Example2 Image Editing Pipeline Documentation

Overview
Example2 is an automated image editing pipeline capable of performing intelligent image editing with background preservation. This pipeline trains text embeddings and a LoRA model, combined with user-provided mask images, to ultimately generate edited images that retain the original background.

Pipeline Execution Flow

Step 1: Data Preparation
Execution Script: prepare_edit.sh
Function Description:
• Generates segmentation files (in JSONL format) for the training dataset
• Extracts multi-scale encoded features from the images
• Prepares the necessary data structures for subsequent training

Key Parameters:
• Automatically sets the base path to the current example directory
• Uses a pre-trained VAE model for feature extraction

Step 2: Text Embedding Training
Execution Script: train_EditInfinity_example2.sh
Function Description:
• Trains the text embedding model to learn the mapping from text to image
• Provides semantic understanding capabilities for image editing

Training Parameters:
• train_textembedding=1: Enables text embedding training
• train_textembedding_iter=10: Trains for 10 iterations
• use_textembedding=0: Does not use pre-trained embeddings during training
• train_lora=0: Does not train LoRA in this stage

Step 3: LoRA Model Training
Execution Script: train_EditInfinity_example2.sh
Function Description:
• Trains the LoRA (Low-Rank Adaptation) model based on the pre-trained text embeddings
• LoRA provides finer control over image editing

Training Parameters:
• train_textembedding=0: Stops text embedding training
• use_textembedding=1: Uses the text embeddings trained in Step 2
• use_textembedding_iter=10: Uses the embedding weights from the 10th iteration
• train_lora=1: Enables LoRA training
• train_lora_iter=50: Trains for 50 iterations

Step 4: Final Image Inference
Execution Script: infer_EditInfinity_example2.sh
Function Description:
• Uses the trained text embeddings and LoRA model
• Combines with the user-provided mask image
• Generates the final edited image while preserving the original background

Inference Parameters:
• infer_function=2: Used for final image generation
• use_concat_embedding=1: Uses concatenated text embeddings
• use_embedding_iter=10: Uses embeddings from the 10th iteration
• use_lora=1: Uses the LoRA model
• use_lora_iter=50: Uses LoRA weights from the 50th iteration

Technical Features

Background Preservation Mechanism
• Requires the user to provide a mask image to specify foreground and background regions
• Intelligently calculates background preservation weights
• Ensures the edited image retains the original background

Two-Stage Training Strategy
1. Text Embedding Training: Learns the mapping from text semantics to visual features
2. LoRA Fine-Tuning Training: Performs detailed adjustments based on the embeddings

Automation Level
• All paths are set automatically, no manual modification required
• Parameters are configured automatically to reduce human error
• Complete end-to-end processing flow

Output Results
After the pipeline execution is complete, the following will be generated in the specified directory:
• Trained model weight files
• Final edited images (with original background preserved)

Usage Instructions
1. Ensure all dependency environments are correctly installed
2. Place the image to be edited at image/original_image.jpg
3. Write the edit prompt into prompt/edit_image_prompt.txt
4. Prepare the mask image (used to specify foreground and background regions)
5. Run edit_pipeline.sh to start the automated processing
6. After processing is complete, results will be saved in the corresponding output directory

Differences from Example3
• Example2: Requires the user to provide a mask image
• Example3: Automatically generates the mask image via an attention mechanism
